{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GalinaChugreeva/CDs-VAE/blob/main/CDs%20VAE%20Chugreeva.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1f668483",
      "metadata": {
        "id": "1f668483"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import KFold\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from itertools import chain\n",
        "import pandas as pd\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e9e5209",
      "metadata": {
        "id": "0e9e5209"
      },
      "source": [
        "# I. Обучение сети на реальных данных"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf840cc2",
      "metadata": {
        "id": "bf840cc2"
      },
      "source": [
        "## 1.1. Датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "00b765ad",
      "metadata": {
        "id": "00b765ad"
      },
      "outputs": [],
      "source": [
        "class CDs_2D_dataset(Dataset):\n",
        "    def __init__(self, annotations_file, spec_dir):\n",
        "      '''annotations_file - the file which contains lables of the samples included in training/validation/test sets'''\n",
        "      self.spec_labels = pd.read_csv(annotations_file, sep=',', decimal=\",\").iloc[:,1:] # labels (concentrations for 4 ions) for all the samples from annotation file (Y_ions.csv)\n",
        "      self.spec_number = pd.read_csv(annotations_file, sep=',', decimal=\",\").iloc[:,0] # numbers for all the samples from annotation file (Y_ions.csv)\n",
        "      self.spec_dir = spec_dir # folder where csv files are located\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.spec_labels)#length of the dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.spec_labels.iloc[idx] # get the label of the sample via sample's index\n",
        "\n",
        "        sp = np.array(pd.read_csv(self.spec_dir + str(self.spec_number[idx])+'_CorrectionData'+'.csv', skiprows=38, sep=';', decimal=\",\").iloc[6:-8,125:325].T, dtype='float32')/4544.595 # get the EEM of the sample via sample's index\n",
        "\n",
        "        sp[sp<0]=0 # here we zero negative values of intensities\n",
        "        spec = torch.from_numpy(sp).unsqueeze(0) # add dimension for channels of cnn\n",
        "\n",
        "\n",
        "        return spec, torch.from_numpy(np.array(label, dtype='float32')) # return spectrum and corresponding labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcf54f28",
      "metadata": {
        "id": "fcf54f28"
      },
      "source": [
        "## 1.2. Архитектура нейросети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cdb88074",
      "metadata": {
        "id": "cdb88074"
      },
      "outputs": [],
      "source": [
        "#2D CNN class (basic)\n",
        "class twoD_CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 94 * 7, 160)\n",
        "        self.fc2 = nn.Linear(160, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0c5da85",
      "metadata": {
        "id": "c0c5da85"
      },
      "source": [
        "## 1.3. Обновление весов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "37ed9a9f",
      "metadata": {
        "id": "37ed9a9f"
      },
      "outputs": [],
      "source": [
        "def reset_weights(m):\n",
        "    for layer in m.children():\n",
        "        if hasattr(layer, 'reset_parameters'):\n",
        "            print(f'Reset trainable parameters of layer = {layer}')\n",
        "            layer.reset_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f4794fc",
      "metadata": {
        "id": "4f4794fc"
      },
      "source": [
        "## 1.4. Запись ответов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8eb3bdab",
      "metadata": {
        "id": "8eb3bdab"
      },
      "outputs": [],
      "source": [
        "def write_predictions(N, model_name, split_path,dataloader, dset):\n",
        "\n",
        "    checkpoint = torch.load(split_path + 'model'+model_name+'.pth')\n",
        "    N.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    last_best_epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    N.eval()\n",
        "\n",
        "    y_ae = np.zeros((1,5))\n",
        "    y_ae_true = np.zeros((1,5))\n",
        "\n",
        "    for specs, labels in dataloader:\n",
        "        outputs = N(specs)\n",
        "        outputs[outputs<0]=0\n",
        "        ae = outputs.detach().numpy()\n",
        "        ae_true = labels.detach().numpy()\n",
        "        y_ae = np.concatenate((y_ae, ae), axis=0)\n",
        "        y_ae_true = np.concatenate((y_ae_true, ae_true), axis=0)\n",
        "\n",
        "    a = ['Cu','Ni','Cr','NO3', 'pH']\n",
        "\n",
        "    pd.DataFrame(y_ae).to_csv(split_path + 'Y_out_'+'_'+dset+'.csv',sep=',', header = a)\n",
        "    pd.DataFrame(y_ae_true).to_csv(split_path + 'Y_true_'+'_'+dset+'.csv',sep=',', header = a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e466bb9d",
      "metadata": {
        "id": "e466bb9d"
      },
      "source": [
        "## 1.5. Кросс-валидация"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qN https://github.com/GalinaChugreeva/CDs-VAE/raw/main/CD_HM_dataset.zip\n",
        "!unzip -qn CD_HM_dataset.zip"
      ],
      "metadata": {
        "id": "uy1tfnRFa6Mn"
      },
      "id": "uy1tfnRFa6Mn",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "46b1fc12",
      "metadata": {
        "id": "46b1fc12"
      },
      "outputs": [],
      "source": [
        "gen_path = ''\n",
        "\n",
        "case_name = '2D_CNN'\n",
        "cnn_2d_path = case_name+'/'\n",
        "\n",
        "Y = pd.read_csv(gen_path+'CD_HM_dataset/'+'Y_ions'+'.csv', sep=',')\n",
        "\n",
        "\n",
        "k_folds = [[42,12],[612,45],[72,172]]\n",
        "\n",
        "fold = k_folds[0]\n",
        "Y_trn, Y_30 = train_test_split(Y, test_size=0.3, random_state=fold[0])\n",
        "Y_vld, Y_tst = train_test_split(Y_30, test_size = 0.3333, random_state=fold[1])\n",
        "\n",
        "for fold in k_folds:\n",
        "    split_path = gen_path+cnn_2d_path+'split_'+ str(fold[0])+'_'+str(fold[1])+ '/'\n",
        "    os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "    Y_trn, Y_30 = train_test_split(Y, test_size=0.3, random_state=fold[0])\n",
        "    Y_vld, Y_tst1 = train_test_split(Y_30, test_size = 0.3333, random_state=fold[1])\n",
        "\n",
        "    a = ['sample_number','Cu','Ni','Cr','NO3', 'pH']\n",
        "\n",
        "    pd.DataFrame(Y_trn).to_csv(split_path + 'Y_trn'+'.csv',sep=',', index=False, header = a)\n",
        "    pd.DataFrame(Y_vld).to_csv(split_path + 'Y_vld'+'.csv',sep=',', index=False, header = a)\n",
        "    pd.DataFrame(Y_tst).to_csv(split_path + 'Y_tst'+'.csv',sep=',', index=False, header = a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eecd87c0",
      "metadata": {
        "id": "eecd87c0"
      },
      "source": [
        "## 1.6. Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0fdad0dc",
      "metadata": {
        "id": "0fdad0dc",
        "outputId": "98d64d5a-de86-4522-a4bc-771b2914ee8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Reset trainable parameters of layer = Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=10528, out_features=160, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=160, out_features=5, bias=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-27406c14e805>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m               \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c01cc4a61d5d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the label of the sample via sample's index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_number\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_CorrectionData'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m325\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4544.595\u001b[0m \u001b[0;31m# get the EEM of the sample via sample's index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;31m# here we zero negative values of intensities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m     \"\"\"\n\u001b[1;32m   1435\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "model = twoD_CNN()\n",
        "\n",
        "loss_function = torch.nn.MSELoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "case_name = '2D_CNN'\n",
        "\n",
        "for fold in k_folds:\n",
        "\n",
        "    cnn_2d_path = case_name+'/'\n",
        "    split_path = gen_path+cnn_2d_path+'split_'+ str(fold[0])+'_'+str(fold[1])+ '/'\n",
        "\n",
        "\n",
        "    training_data = CDs_2D_dataset(split_path+'Y_trn'+'.csv', gen_path + 'CD_HM_dataset/')\n",
        "    validation_data = CDs_2D_dataset(split_path+'Y_vld'+'.csv', gen_path + 'CD_HM_dataset/')\n",
        "    test_data = CDs_2D_dataset(split_path+'Y_tst'+'.csv', gen_path + 'CD_HM_dataset/')\n",
        "\n",
        "    train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "    validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "\n",
        "    for init_number in range(0,2):\n",
        "\n",
        "      init_path = split_path + str(init_number)+'/'\n",
        "      os.makedirs(init_path, exist_ok=True)\n",
        "\n",
        "      test_stop = 100\n",
        "      max_val_loss = 10000.0\n",
        "\n",
        "      split_name = 'split_'+ str(fold[0])+'_'+str(fold[1])\n",
        "      init_name = '_' + str(init_number)\n",
        "      model_name = '_2D_CNN'\n",
        "\n",
        "\n",
        "      for epoch_step in range(0, 5000, test_stop):\n",
        "\n",
        "          if epoch_step!=0:\n",
        "              checkpoint = torch.load(init_path + 'model'+model_name+'.pth')\n",
        "              model.load_state_dict(checkpoint['model_state_dict'])\n",
        "              optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "              last_best_epoch = checkpoint['epoch']\n",
        "              loss = checkpoint['loss']\n",
        "              model.train()\n",
        "\n",
        "              if last_best_epoch + test_stop > ep:\n",
        "                  for ep in range(epoch_step, epoch_step+test_stop):\n",
        "                      for _, data in enumerate(train_dataloader, 0):\n",
        "                          inputs, labels = data\n",
        "                          optimizer.zero_grad()\n",
        "                          outputs = model(inputs)\n",
        "                          loss = loss_function(outputs, labels)\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "                      dl = 0\n",
        "                      val_loss = 0.0\n",
        "                      for specs, labels in validation_dataloader:\n",
        "                          val_loss += loss_function(model(specs),labels)\n",
        "                          dl+=1\n",
        "                      val_loss = val_loss/dl\n",
        "\n",
        "\n",
        "\n",
        "                      if val_loss.item() <= max_val_loss:\n",
        "                          torch.save({'epoch': ep,\n",
        "                            'model_state_dict': model.state_dict(),\n",
        "                            'optimizer_state_dict': optimizer.state_dict(),\n",
        "                            'loss': loss}, init_path + 'model'+model_name+'.pth')\n",
        "                          max_val_loss = val_loss.item()\n",
        "              else: continue\n",
        "\n",
        "          if epoch_step==0:\n",
        "              model.apply(reset_weights)\n",
        "\n",
        "              for ep in range(epoch_step, test_stop):\n",
        "                  for _, data in enumerate(train_dataloader, 0):\n",
        "                      inputs, labels = data\n",
        "                      optimizer.zero_grad()\n",
        "                      outputs = model(inputs)\n",
        "                      loss = loss_function(outputs, labels)\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "                  dl = 0\n",
        "                  val_loss = 0.0\n",
        "                  for specs, labels in validation_dataloader:\n",
        "                      val_loss += loss_function(model(specs),labels)\n",
        "                      dl+=1\n",
        "                  val_loss = val_loss/dl\n",
        "\n",
        "                  if val_loss.item() <= max_val_loss:\n",
        "                      torch.save({'epoch': ep,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'loss': loss}, init_path + 'model'+model_name+'.pth')\n",
        "                      max_val_loss = val_loss.item()\n",
        "\n",
        "\n",
        "      write_predictions(model, model_name, init_path, train_dataloader, dset = 'trn')\n",
        "      write_predictions(model, model_name, init_path, validation_dataloader, dset ='vld')\n",
        "      write_predictions(model, model_name, init_path, test_dataloader, dset ='tst')\n",
        "\n",
        "\n",
        "      print(epoch_step, init_number, fold)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfcb5405",
      "metadata": {
        "id": "cfcb5405"
      },
      "source": [
        "## 1.7. Подсчет ошибок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5cb4fd97",
      "metadata": {
        "id": "5cb4fd97",
        "outputId": "83352121-2e52-491c-bef8-9606104649cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-21e97424d57e>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpath_true_tst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2D_CNN/split_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/Y_true__tst.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mY_true_tst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_true_tst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpath_out_tst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2D_CNN/split_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/Y_out__tst.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2D_CNN/split_42_12/0/Y_true__tst.csv'"
          ]
        }
      ],
      "source": [
        "cu_errors = []\n",
        "ni_errors = []\n",
        "cr_errors = []\n",
        "no3_errors = []\n",
        "ph_errors = []\n",
        "\n",
        "mnozh_init = []\n",
        "folds = []\n",
        "\n",
        "for fold in k_folds:\n",
        "    for i in range(0, 2):\n",
        "\n",
        "        path_true_tst = '2D_CNN/split_' + str(fold[0])+'_'+str(fold[1])+ '/' + str(i) + '/Y_true__tst.csv'\n",
        "        Y_true_tst = pd.read_csv(path_true_tst)\n",
        "\n",
        "        path_out_tst = '2D_CNN/split_' + str(fold[0])+'_'+str(fold[1])+ '/' + str(i) + '/Y_out__tst.csv'\n",
        "        Y_out_tst = pd.read_csv(path_out_tst)\n",
        "\n",
        "        cu_err = np.mean(sklearn.metrics.mean_absolute_error(Y_true_tst['Cu'], Y_out_tst['Cu']))\n",
        "        ni_err = np.mean(sklearn.metrics.mean_absolute_error(Y_true_tst['Ni'], Y_out_tst['Ni']))\n",
        "        cr_err = np.mean(sklearn.metrics.mean_absolute_error(Y_true_tst['Cr'], Y_out_tst['Cr']))\n",
        "        no3_err = np.mean(sklearn.metrics.mean_absolute_error(Y_true_tst['NO3'], Y_out_tst['NO3']))\n",
        "        ph_err = np.mean(sklearn.metrics.mean_absolute_error(Y_true_tst['pH'], Y_out_tst['pH']))\n",
        "\n",
        "\n",
        "        cu_errors.append(cu_err)\n",
        "        ni_errors.append(ni_err)\n",
        "        cr_errors.append(cr_err)\n",
        "        no3_errors.append(no3_err)\n",
        "        ph_errors.append(ph_err)\n",
        "\n",
        "        mnozh_init.append(i)\n",
        "        folds.append(fold)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf9150d",
      "metadata": {
        "id": "bbf9150d"
      },
      "source": [
        "# II. Увеличение представительности набора с помощью автоэнкодеров"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc2c5e35",
      "metadata": {
        "id": "dc2c5e35"
      },
      "source": [
        "## 2.1. Encoder & decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62cca814",
      "metadata": {
        "id": "62cca814"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_size):\n",
        "        super().__init__()\n",
        "        self.latent_size = latent_size\\\n",
        "\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, padding='same'),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, padding='same'),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding='same'),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "\n",
        "            nn.Linear(32 * 25 * 3, self.latent_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "        self.linear = nn.Linear(self.latent_size, 32 * 25 * 3)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Upsample(size=(36, 4), mode='bicubic'),\n",
        "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Upsample(size=(88, 10), mode='bicubic'),\n",
        "            nn.ConvTranspose2d(in_channels=16, out_channels=6, kernel_size=3),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Upsample(size=(200, 27), mode='bicubic'),\n",
        "            nn.ConvTranspose2d(in_channels=6, out_channels=1, kernel_size=3),\n",
        "            nn.Upsample(size=(200, 27), mode='bicubic'),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = x.view(-1, 32, 25, 3)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f7a400",
      "metadata": {
        "id": "64f7a400"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "latent_size = 100\n",
        "learning_rate = 1e-4\n",
        "encoder = Encoder(latent_size=latent_size)\n",
        "decoder = Decoder(latent_size=latent_size)\n",
        "\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "print(\">>> Encoder\")\n",
        "print(summary(encoder, (1, 201, 27)))\n",
        "print(\">>> Decoder\")\n",
        "print(summary(decoder, (1, latent_size)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa521450",
      "metadata": {
        "id": "aa521450"
      },
      "source": [
        "## 2.2 Реализация VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea6bdc2f",
      "metadata": {
        "id": "ea6bdc2f"
      },
      "outputs": [],
      "source": [
        "class VAEEncoder(Encoder):\n",
        "    def __init__(self, latent_size):\n",
        "        if latent_size % 2 != 0:\n",
        "            raise Exception(\"Latent size for VAEEncoder must be even\")\n",
        "        super().__init__(latent_size)\n",
        "\n",
        "\n",
        "def vae_split(latent):\n",
        "    size = latent.shape[1] // 2\n",
        "    mu = latent[:, :size]\n",
        "    log_var = latent[:, size:]\n",
        "    return mu, log_var\n",
        "\n",
        "\n",
        "def vae_reparametrize(mu, log_var):\n",
        "    sigma = torch.exp(0.5 * log_var)\n",
        "    eps = torch.randn(mu.shape[0], mu.shape[1]).to(device)\n",
        "    return eps * sigma + mu\n",
        "\n",
        "\n",
        "def vae_pass_handler(encoder, decoder, data, *args, **kwargs):\n",
        "    latent = encoder(data)\n",
        "    mu, log_var = vae_split(latent)\n",
        "    sample = vae_reparametrize(mu, log_var)\n",
        "    recon = decoder(sample)\n",
        "    return latent, recon\n",
        "\n",
        "\n",
        "\n",
        "def ae_pass_handler(encoder, decoder, data, *args, **kwargs):\n",
        "    latent = encoder(data)\n",
        "    recon = decoder(latent)\n",
        "    return latent, recon\n",
        "\n",
        "\n",
        "\n",
        "def kld_loss(mu, log_var):\n",
        "    var = log_var.exp()\n",
        "    kl_loss = torch.mean(-0.5 * torch.sum(log_var - var - mu**2 + 1, dim=1), dim=0)\n",
        "    return kl_loss\n",
        "\n",
        "\n",
        "def vae_loss_handler(data, recon, latent, kld_weight=0.5, *args, **kwargs):\n",
        "    mu, log_var = vae_split(latent)\n",
        "    kl_loss = kld_loss(mu, log_var)\n",
        "    loss = F.binary_cross_entropy(recon, data) + kld_weight * kl_loss\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ae_loss_handler(data, recon, *args, **kwargs):\n",
        "    loss = F.mse_loss(recon, data)\n",
        "    #loss = F.binary_cross_entropy(recon, data)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d5d1d71",
      "metadata": {
        "id": "3d5d1d71"
      },
      "source": [
        "## 2.3. Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62fa2dc3",
      "metadata": {
        "id": "62fa2dc3"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "def run_eval(\n",
        "    encoder,\n",
        "    decoder,\n",
        "    loader,\n",
        "    single_pass_handler,\n",
        "    return_real=True,\n",
        "    return_recon=True,\n",
        "    return_latent=True,\n",
        "    return_labels=True,\n",
        "    return_idx=True,\n",
        "):\n",
        "    if return_real:\n",
        "        real_list = []\n",
        "    if return_recon:\n",
        "        recon_list = []\n",
        "    if return_latent:\n",
        "        latent_list = []\n",
        "    if return_labels:\n",
        "        labels_list = []\n",
        "    if return_idx:\n",
        "        labels_idx = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (idx, data, labels) in enumerate(loader):\n",
        "            if return_idx:\n",
        "                labels_idx.append(idx.numpy())\n",
        "            if return_labels:\n",
        "                labels_list.append(labels.numpy())\n",
        "            if return_real:\n",
        "                real_list.append(data.numpy())\n",
        "\n",
        "            idx = idx.to(device)\n",
        "            data = data.to(device)\n",
        "            labels = labels.to(device)\n",
        "            latent, recon = single_pass_handler(encoder, decoder, data, labels)\n",
        "\n",
        "            if return_latent:\n",
        "                latent_list.append(latent.cpu().numpy())\n",
        "            if return_recon:\n",
        "                recon_list.append(recon.cpu().numpy())\n",
        "\n",
        "    result = {}\n",
        "    if return_real:\n",
        "        real = np.concatenate(real_list)\n",
        "        result[\"real\"] = real.squeeze()\n",
        "    if return_latent:\n",
        "        latent = np.concatenate(latent_list)\n",
        "        result[\"latent\"] = latent\n",
        "    if return_recon:\n",
        "        recon = np.concatenate(recon_list)\n",
        "        result[\"recon\"] = recon.squeeze()\n",
        "    if return_labels:\n",
        "        labels = np.concatenate(labels_list)\n",
        "        result[\"labels\"] = labels\n",
        "    if return_idx:\n",
        "        idx = np.concatenate(labels_idx)\n",
        "        result[\"idx\"] = idx\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63c128c2",
      "metadata": {
        "id": "63c128c2"
      },
      "outputs": [],
      "source": [
        "def train_and_save(epochs,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    dataloader,\n",
        "    single_pass_handler,\n",
        "    loss_handler,\n",
        "    latent_size,\n",
        "    learning_rate,\n",
        "    path_for_save,\n",
        "    log_interval=1\n",
        "):\n",
        "\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    ep_array = []\n",
        "    train_loss_array = []\n",
        "    val_loss_array = []\n",
        "    test_loss_array = []\n",
        "\n",
        "\n",
        "    if encoder==VAEEncoder:\n",
        "        encoder = encoder(latent_size=2*latent_size)\n",
        "    else:\n",
        "        encoder = encoder(latent_size=latent_size)\n",
        "    decoder = decoder(latent_size=latent_size)\n",
        "\n",
        "    encoder = encoder.to(device)\n",
        "    decoder = decoder.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(\n",
        "        chain(encoder.parameters(), decoder.parameters()), lr=learning_rate\n",
        "    )\n",
        "\n",
        "    loader=train_loader\n",
        "    val_loader=val_loader\n",
        "\n",
        "    for ep in range(0, epochs):\n",
        "        current_train_loss = 0\n",
        "        for train_batch_idx, (idx, data, labels) in enumerate(loader):\n",
        "            batch_size = data.size(0)\n",
        "            optimizer.zero_grad()\n",
        "            data = data.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            latent, recon = single_pass_handler(\n",
        "                encoder, decoder, data, labels\n",
        "            )\n",
        "\n",
        "            loss = loss_handler(data, recon, latent)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            current_train_loss += loss.item()\n",
        "\n",
        "\n",
        "        current_val_loss = 0\n",
        "        for val_batch_idx, (idx, data_val, labels_val) in enumerate(val_loader):\n",
        "            encoder = encoder.eval()\n",
        "            decoder = decoder.eval()\n",
        "\n",
        "\n",
        "            data_val = data_val.to(device)\n",
        "            labels_val = labels_val.to(device)\n",
        "            latent_val, recon_val = single_pass_handler(\n",
        "                encoder, decoder, data_val, labels_val\n",
        "            )\n",
        "\n",
        "\n",
        "            loss_val = loss_handler(data_val, recon_val, latent_val)\n",
        "\n",
        "            current_val_loss += loss_val.item()\n",
        "\n",
        "        ep_array.append(ep)\n",
        "        train_loss_array.append(current_train_loss / (train_batch_idx + 1))\n",
        "        val_loss_array.append(current_val_loss / (val_batch_idx + 1))\n",
        "\n",
        "        if ep%log_interval==0:\n",
        "            print(f\"Train Epoch: {ep}:   Loss_train: {train_loss_array[-1]:.6f}   Loss_val: {val_loss_array[-1]:.6f}\")\n",
        "\n",
        "    current_test_loss = 0\n",
        "    for test_batch_idx, (idx, data_test, labels_test) in enumerate(test_dataloader):\n",
        "        encoder = encoder.eval()\n",
        "        decoder = decoder.eval()\n",
        "\n",
        "\n",
        "        data_test = data_test.to(device)\n",
        "        labels_test = labels_test.to(device)\n",
        "        latent_test, recon_test = single_pass_handler(\n",
        "            encoder, decoder, data_test, labels_test\n",
        "        )\n",
        "\n",
        "\n",
        "        loss_test = loss_handler(data_test, recon_test, latent_test)\n",
        "        current_test_loss += loss_test.item()\n",
        "\n",
        "\n",
        "    test_loss = (current_test_loss / (test_batch_idx + 1))\n",
        "    print(f\"Test_loss: {test_loss:.6f} learning_rate: {learning_rate:.6f} latent_size: {latent_size:.0f}\")\n",
        "\n",
        "    plt.plot(ep_array, train_loss_array)\n",
        "    plt.plot(ep_array, val_loss_array)\n",
        "    plt.legend([\"train\", \"val\"])\n",
        "    plt.title([\"latent_size: {:.0f}\".format(latent_size), \"learning_rate:{}\".format(learning_rate)])\n",
        "    plt.yscale(\"log\")\n",
        "    plt.ylim(0.07, 0.12)\n",
        "    plt.show()\n",
        "\n",
        "    encoder = encoder.eval()\n",
        "    decoder = decoder.eval()\n",
        "\n",
        "\n",
        "    run_res = run_eval(encoder, decoder, dataloader, single_pass_handler)\n",
        "\n",
        "    os.makedirs(path_for_save, exist_ok=True)\n",
        "\n",
        "    for idx in run_res[\"idx\"]:\n",
        "        Z_recon = run_res[\"recon\"][idx].T\n",
        "        pd.DataFrame(Z_recon).to_csv(path_for_save+'/'+str(idx+1001)+'.csv') #index=False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb843447",
      "metadata": {
        "id": "bb843447"
      },
      "outputs": [],
      "source": [
        "train_and_save(epochs = 1000,\n",
        "    encoder = VAEEncoder,\n",
        "    decoder = Decoder,\n",
        "    train_loader = train_dataloader,\n",
        "    val_loader = validation_dataloader,\n",
        "    dataloader = dataloader,\n",
        "    single_pass_handler = vae_pass_handler,\n",
        "    loss_handler = vae_loss_handler,\n",
        "    latent_size = 300,\n",
        "    learning_rate = 0.002,\n",
        "    path_for_save = '2D_CNN_gen',\n",
        "    log_interval=100\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fc9fd53",
      "metadata": {
        "id": "4fc9fd53"
      },
      "source": [
        "# III. Определяем концентрацию ионов и рН в сгенерированных спектрах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36bdb164",
      "metadata": {
        "id": "36bdb164",
        "outputId": "1917d5ee-1273-4ab5-b0c1-c5806f9a7b18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "twoD_CNN(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=10528, out_features=160, bias=True)\n",
              "  (fc2): Linear(in_features=160, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_check = twoD_CNN()\n",
        "\n",
        "path = '2D_CNN/split_42_12/0/'\n",
        "checkpoint = torch.load(path + 'model_2D_CNN'+'.pth')\n",
        "model_check.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "#load optimizer\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "last_best_epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "model_check.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3557e1f",
      "metadata": {
        "id": "f3557e1f"
      },
      "outputs": [],
      "source": [
        "file_x = '2D_CNN_gen'\n",
        "file_y = 'CD_HM_dataset/Y_ions.csv'\n",
        "\n",
        "data =  CDs_2D_dataset(file_y, file_x)\n",
        "\n",
        "dataloader = DataLoader(data, batch_size=1000, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c37e3afa",
      "metadata": {
        "id": "c37e3afa"
      },
      "outputs": [],
      "source": [
        "for specs, labels in dataloader:\n",
        "    outputs = model(specs)\n",
        "    outputs[outputs<0]=0 #we zero negative outputs as they are impossible for concentration values\n",
        "    ae = outputs.detach().numpy()\n",
        "    ae_true = labels.detach().numpy()\n",
        "\n",
        "a = ['Cu','Ni','Cr','NO3', 'pH']\n",
        "split_path = '2D_CNN_gen/'\n",
        "\n",
        "pd.DataFrame(ae).to_csv(split_path + 'Y_out'+'.csv',sep=',', header = a)\n",
        "pd.DataFrame(ae_true).to_csv(split_path + 'Y_out_true'+'.csv',sep=',', header = a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c8b4ac7",
      "metadata": {
        "id": "7c8b4ac7"
      },
      "source": [
        "# IV. Обучение новой модели на расширенном наборе данных"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# создадим новую папку, в которой будут все спектры\n",
        "os.makedirs('2D_CNN_gen_and_origin', exist_ok=True)\n",
        "# скопируем в эту папку сгенерированные спектры\n",
        "shutil.copy('2D_CNN_gen', '2D_CNN_gen_and_origin', follow_symlinks=True)"
      ],
      "metadata": {
        "id": "F4Bl14IHY-si"
      },
      "id": "F4Bl14IHY-si",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# скопируем в эту папку реальные спектры\n",
        "files=glob.glob('CD_HM_dataset/*.csv')\n",
        "\n",
        "for i in trange(len(files)):\n",
        "    df=pd.read_csv(files[i], skiprows=38,sep=';', decimal=',').iloc[6:-8,125:325]/4544.595\n",
        "    df.to_csv('2D_CNN_gen_and_origin'+'/'+files[i][14:-19]+'.csv')"
      ],
      "metadata": {
        "id": "OqGMH6YbY-w3"
      },
      "id": "OqGMH6YbY-w3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создадим в этой папке таблицу с таргетами\n",
        "Y_out = pd.read_csv('2D_CNN_gen/Y_out.csv')\n",
        "Y_out_true = pd.read_csv('2D_CNN_gen/Y_out_true.csv')\n",
        "pd.concat([\n",
        "    Y_out,\n",
        "    Y_out_true\n",
        "]).to_csv('2D_CNN_gen_and_origin/Y.csv')"
      ],
      "metadata": {
        "id": "vJOpl23qbXwh"
      },
      "id": "vJOpl23qbXwh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d28522",
      "metadata": {
        "id": "98d28522"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "gen_path = ''\n",
        "\n",
        "case_name = '2D_CNN_gen_and_origin'\n",
        "cnn_2d_path = case_name+'/'\n",
        "\n",
        "Y = pd.read_csv(gen_path+cnn_2d_path+'Y.csv', sep=',')\n",
        "\n",
        "\n",
        "k_folds = [[42,12],[612,45],[72,172]]\n",
        "\n",
        "\n",
        "for fold in k_folds:\n",
        "    split_path = gen_path+cnn_2d_path+'split_'+ str(fold[0])+'_'+str(fold[1])+ '/'\n",
        "    os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "    Y_trn, Y_vld = train_test_split(Y, test_size=0.1, random_state=fold[0])\n",
        "\n",
        "    a = ['sample_number','Cu','Ni','Cr','NO3', 'pH']\n",
        "\n",
        "    pd.DataFrame(Y_trn).to_csv(split_path + 'Y_trn'+'.csv',sep=',', index=False, header = a)\n",
        "    pd.DataFrame(Y_vld).to_csv(split_path + 'Y_vld'+'.csv',sep=',', index=False, header = a)\n",
        "    pd.DataFrame(Y_tst).to_csv(split_path + 'Y_tst'+'.csv',sep=',', index=False, header = a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b19f19a8",
      "metadata": {
        "id": "b19f19a8"
      },
      "outputs": [],
      "source": [
        "class CDS_2D_Dataset_generated(Dataset):\n",
        "    def __init__(self, annotations_file, spec_dir):\n",
        "      '''annotations_file - the file which contains lables of the samples included in training/validation/test sets'''\n",
        "      self.spec_labels = pd.read_csv(annotations_file, sep=',', decimal=\",\").iloc[:,1:] # labels (concentrations for 4 ions) for all the samples from annotation file (Y_ions.csv)\n",
        "      self.spec_number = pd.read_csv(annotations_file, sep=',', decimal=\",\").iloc[:,0] # numbers for all the samples from annotation file (Y_ions.csv)\n",
        "      self.spec_dir = spec_dir # folder where csv files are located\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.spec_labels)#length of the dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.spec_labels.iloc[idx] # get the label of the sample via sample's index\n",
        "\n",
        "        sp = np.array(pd.read_csv(self.spec_dir + str(self.spec_number[idx])+'.csv').iloc[:, 1:].T , dtype='float32')# get the EEM of the sample via sample's index\n",
        "\n",
        "        sp[sp<0]=0 # here we zero negative values of intensities\n",
        "        spec = torch.from_numpy(sp).unsqueeze(0) # add dimension for channels of cnn\n",
        "\n",
        "        return spec, torch.from_numpy(np.array(label, dtype='float32')) # return spectrum and corresponding labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df00b2d0",
      "metadata": {
        "id": "df00b2d0",
        "outputId": "cfe33181-1c0b-4451-c453-b65abdefecf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n",
            "Reset trainable parameters of layer = Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=10528, out_features=160, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=160, out_features=5, bias=True)\n",
            "4900 0 [42, 12]\n",
            "Reset trainable parameters of layer = Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=10528, out_features=160, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=160, out_features=5, bias=True)\n",
            "4900 1 [42, 12]\n",
            "Reset trainable parameters of layer = Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=10528, out_features=160, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=160, out_features=5, bias=True)\n",
            "4900 0 [612, 45]\n",
            "Reset trainable parameters of layer = Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=10528, out_features=160, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=160, out_features=5, bias=True)\n",
            "4900 1 [612, 45]\n",
            "Reset trainable parameters of layer = Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=10528, out_features=160, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=160, out_features=5, bias=True)\n",
            "4900 0 [72, 172]\n",
            "Reset trainable parameters of layer = Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=10528, out_features=160, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=160, out_features=5, bias=True)\n",
            "4900 1 [72, 172]\n"
          ]
        }
      ],
      "source": [
        "#device = torch.device('mps')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "model = twoD_CNN()\n",
        "\n",
        "loss_function = torch.nn.MSELoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "case_name = '2D_CNN_gen_and_origin'\n",
        "\n",
        "for fold in k_folds:\n",
        "\n",
        "    cnn_2d_path = case_name+'/'\n",
        "    split_path = gen_path+cnn_2d_path+'split_'+ str(fold[0])+'_'+str(fold[1])+ '/'\n",
        "\n",
        "\n",
        "    training_data = CDS_2D_Dataset_generated(split_path+'Y_trn'+'.csv', gen_path + case_name)\n",
        "    validation_data = CDS_2D_Dataset_generated(split_path+'Y_vld'+'.csv', gen_path + case_name)\n",
        "    test_data = CDS_2D_Dataset_generated(split_path+'Y_tst'+'.csv', gen_path + case_name)\n",
        "\n",
        "    train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "    validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "\n",
        "    for init_number in range(0,2):\n",
        "\n",
        "      init_path = split_path + str(init_number)+'/'\n",
        "      os.makedirs(init_path, exist_ok=True)\n",
        "\n",
        "      test_stop = 100\n",
        "      max_val_loss = 10000.0\n",
        "\n",
        "      split_name = 'split_'+ str(fold[0])+'_'+str(fold[1])\n",
        "      init_name = '_' + str(init_number)\n",
        "      model_name = '_2D_CNN'\n",
        "\n",
        "\n",
        "      for epoch_step in range(0, 5000, test_stop):\n",
        "\n",
        "          if epoch_step!=0:\n",
        "              checkpoint = torch.load(init_path + 'model'+model_name+'.pth')\n",
        "              model.load_state_dict(checkpoint['model_state_dict'])\n",
        "              optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "              last_best_epoch = checkpoint['epoch']\n",
        "              loss = checkpoint['loss']\n",
        "              model.train()\n",
        "\n",
        "              if last_best_epoch + test_stop > ep:\n",
        "                  for ep in range(epoch_step, epoch_step+test_stop):\n",
        "                      for _, data in enumerate(train_dataloader, 0):\n",
        "                          inputs, labels = data\n",
        "                          optimizer.zero_grad()\n",
        "                          outputs = model(inputs)\n",
        "                          loss = loss_function(outputs, labels)\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "                      dl = 0\n",
        "                      val_loss = 0.0\n",
        "                      for specs, labels in validation_dataloader:\n",
        "                          val_loss += loss_function(model(specs),labels)\n",
        "                          dl+=1\n",
        "                      val_loss = val_loss/dl\n",
        "\n",
        "\n",
        "\n",
        "                      if val_loss.item() <= max_val_loss:\n",
        "                          torch.save({'epoch': ep,\n",
        "                            'model_state_dict': model.state_dict(),\n",
        "                            'optimizer_state_dict': optimizer.state_dict(),\n",
        "                            'loss': loss}, init_path + 'model'+model_name+'.pth')\n",
        "                          max_val_loss = val_loss.item()\n",
        "              else: continue\n",
        "\n",
        "          if epoch_step==0:\n",
        "              model.apply(reset_weights)\n",
        "\n",
        "              for ep in range(epoch_step, test_stop):\n",
        "                  for _, data in enumerate(train_dataloader, 0):\n",
        "                      inputs, labels = data\n",
        "                      optimizer.zero_grad()\n",
        "                      outputs = model(inputs)\n",
        "                      loss = loss_function(outputs, labels)\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "                  dl = 0\n",
        "                  val_loss = 0.0\n",
        "                  for specs, labels in validation_dataloader:\n",
        "                      val_loss += loss_function(model(specs),labels)\n",
        "                      dl+=1\n",
        "                  val_loss = val_loss/dl\n",
        "\n",
        "                  if val_loss.item() <= max_val_loss:\n",
        "                      torch.save({'epoch': ep,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'loss': loss}, init_path + 'model'+model_name+'.pth')\n",
        "                      max_val_loss = val_loss.item()\n",
        "\n",
        "\n",
        "      write_predictions(model, model_name, init_path, train_dataloader, dset = 'trn')\n",
        "      write_predictions(model, model_name, init_path, validation_dataloader, dset ='vld')\n",
        "      write_predictions(model, model_name, init_path, test_dataloader, dset ='tst')\n",
        "\n",
        "\n",
        "      print(epoch_step, init_number, fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf19083",
      "metadata": {
        "id": "dbf19083"
      },
      "outputs": [],
      "source": [
        "cu_errors_gen = []\n",
        "ni_errors_gen = []\n",
        "cr_errors_gen = []\n",
        "no3_errors_gen = []\n",
        "ph_errors_gen = []\n",
        "\n",
        "mnozh_init = []\n",
        "folds = []\n",
        "\n",
        "for fold in k_folds:\n",
        "    for i in range(0, 2):\n",
        "\n",
        "        path_true_tst_gen = case_name + '/split_' + str(fold[0])+'_'+str(fold[1])+ '/' + str(i) + '/Y_true__tst.csv'\n",
        "        Y_true_tst_gen = pd.read_csv(path_true_tst_gen)\n",
        "\n",
        "        path_out_tst_gen = case_name + '/split_' + str(fold[0])+'_'+str(fold[1])+ '/' + str(i) + '/Y_out__tst.csv'\n",
        "        Y_out_tst_gen = pd.read_csv(path_out_tst_gen)\n",
        "\n",
        "        cu_err = np.mean(sklearn.metrics.mean_absolute_error(Y_true_tst_gen['Cu'], Y_out_tst_gen['Cu']))\n",
        "        ni_erar = np.mean(sklearn.metrics.mean_absolute_error(Y_true_tst_gen['Ni'], Y_out_tst_gen['Ni']))\n",
        "        cr_err = np.mean(sklearn.metrics.mean_absolute_error(Y_true_tst_gen['Cr'], Y_out_tst_gen['Cr']))\n",
        "        no3_err = np.mean(sklearn.metrics.mean_absolute_error(Y_true_tst_gen['NO3'], Y_out_tst_gen['NO3']))\n",
        "        ph_err = np.mean(sklearn.metrics.mean_absolute_error(Y_true_tst_gen['pH'], Y_out_tst_gen['pH']))\n",
        "\n",
        "\n",
        "        cu_errors_gen.append(cu_err)\n",
        "        ni_errors_gen.append(ni_err)\n",
        "        cr_errors_gen.append(cr_err)\n",
        "        no3_errors_gen.append(no3_err)\n",
        "        ph_errors_gen.append(ph_err)\n",
        "\n",
        "        mnozh_init.append(i)\n",
        "        folds.append(fold)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "431865f5",
      "metadata": {
        "id": "431865f5",
        "outputId": "f3d743aa-74d3-454d-83e4-3ef217540921"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "species = (r'$Cu^2$', r'$Ni^2$', r'$Cr^3$', r'$NO_3$', \"pH\")\n",
        "penguin_means = {\n",
        "    'Экспериментальные спектры': (np.round(np.mean(cu_errors), 2), np.round(np.mean(ni_errors), 2), np.round(np.mean(cr_errors), 2), np.round(np.mean(no3_errors), 2), np.round(np.mean(ph_errors), 2)),\n",
        "    'Экспериментальные + сгенерированные': (np.round(np.mean(cu_errors_gen), 2), np.round(np.mean(ni_errors_gen), 2), np.round(np.mean(cr_errors_gen), 2), np.round(np.mean(no3_errors_gen), 2), np.round(np.mean(ph_errors_gen), 2)\n",
        "),\n",
        "}\n",
        "\n",
        "x = np.arange(len(species))\n",
        "width = 0.25\n",
        "multiplier = 1\n",
        "\n",
        "fig, ax = plt.subplots(layout='constrained')\n",
        "\n",
        "for attribute, measurement in penguin_means.items():\n",
        "    offset = width * multiplier\n",
        "    rects = ax.bar(x + offset, measurement, width, label=attribute, yerr = [np.round(np.std(cu_errors), 2), np.round(np.std(ni_errors), 2)/2, np.round(np.std(cr_errors), 2), np.round(np.std(no3_errors)/3, 2), np.round(np.std(ph_errors), 2)])\n",
        "    ax.bar_label(rects, padding=3)\n",
        "    multiplier += 1\n",
        "\n",
        "ax.set_ylabel('MAE (mM)')\n",
        "ax.set_xticks(x + width, species)\n",
        "ax.legend(loc='upper left', ncols=3)\n",
        "ax.set_ylim(0, 2.2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f44d15",
      "metadata": {
        "id": "d9f44d15"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}